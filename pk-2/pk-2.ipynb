{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0979a7a",
   "metadata": {},
   "source": [
    "# Рубежный контроль №2\n",
    "**Студент**: Хуан Яовэнь   \n",
    "**Группа**: ИУ5И-21М   \n",
    "\n",
    "Тема: Методы обработки текстов.\n",
    "\n",
    "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
    "\n",
    "Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer.\n",
    "\n",
    "**Классификатор**:LogisticRegression,Multinomial Naive Bayes - MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d574919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a1f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9370656",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfa76f",
   "metadata": {},
   "source": [
    "Работа с наборами данных\"Amazon Alexa Reviews\" из Kaggle.  \n",
    "About the Data\n",
    "\n",
    "This dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc. for learning how to train Machine for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aae46c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_rev=pd.read_csv(\"amazon_alexa.tsv\", sep='\\t')\n",
    "amazon_rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f45bbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_rev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118fa622",
   "metadata": {},
   "source": [
    "Только держать колонки \"verified_reviews\" и \"feedback\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115dda00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  value\n",
       "0                                      Love my Echo!      1\n",
       "1                                          Loved it!      1\n",
       "2  Sometimes while playing a game, you can answer...      1\n",
       "3  I have had a lot of fun with this thing. My 4 ...      1\n",
       "4                                              Music      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df = pd.DataFrame(amazon_rev,columns=['verified_reviews','feedback'])\n",
    "amazon_df.columns = ['text','value']\n",
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b773e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Loved it!',\n",
       " 'Sometimes while playing a game, you can answer a question correctly but Alexa says you got it wrong and answers the same as you.  I like being able to turn lights on and off while away from home.',\n",
       " 'I have had a lot of fun with this thing. My 4 yr old learns about dinosaurs, i control the lights and play games like categories. Has nice sound when playing music as well.',\n",
       " 'Music',\n",
       " 'I received the echo as a gift. I needed another Bluetooth or something to play music easily accessible, and found this smart speaker. Can’t wait to see what else it can do.',\n",
       " 'Without having a cellphone, I cannot use many of her features. I have an iPad but do not see that of any use.  It IS a great alarm.  If u r almost deaf, you can hear her alarm in the bedroom from out in the living room, so that is reason enough to keep her.It is fun to ask random questions to hear her response.  She does not seem to be very smartbon politics yet.',\n",
       " \"I think this is the 5th one I've purchased. I'm working on getting one in every room of my house. I really like what features they offer specifily playing music on all Echos and controlling the lights throughout my house.\",\n",
       " 'looks great',\n",
       " 'Love it! I’ve listened to songs I haven’t heard since childhood! I get the news, weather, information! It’s great!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сформируем общий словарь\n",
    "vocab_list = amazon_df['text'].tolist()\n",
    "vocab_list[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53bc8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 4044\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(vocab_list)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74826e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my=2320\n",
      "echo=1160\n",
      "loved=2151\n",
      "it=1933\n",
      "sometimes=3289\n",
      "while=3945\n",
      "playing=2640\n",
      "game=1504\n",
      "you=4028\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f988d",
   "metadata": {},
   "source": [
    "### Векторизация текста на основе модели \"мешка слов\"\n",
    "Векторизация текста поддерживается библиотекой scikit-learn.\n",
    "\n",
    "### Использование класса CountVectorizer\n",
    "Подсчитывает количество слов словаря, входящих в данный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5cb34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = vocabVect.transform(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ca73c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3150x4044 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 60852 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5994d3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03c7c0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4044"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки\n",
    "len(test_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d658137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Непустые значения нулевой строки\n",
    "[i for i in test_features.todense()[0].getA1() if i>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9d66c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accustom',\n",
       " 'acknowledge',\n",
       " 'acoustical',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabVect.get_feature_names()[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb86c49",
   "metadata": {},
   "source": [
    "### Использование класса TfidfVectorizer\n",
    "Вычисляет специфичность текста в корпусе текстов на основе метрики TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a91187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3150x78649 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 200215 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(ngram_range=(1,3))\n",
    "tfidf_ngram_features = tfidfv.fit_transform(vocab_list)\n",
    "tfidf_ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5a9d405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ngram_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14476192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78649"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки\n",
    "len(tfidf_ngram_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28a3430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29583592663701436,\n",
       " 0.25907502163192725,\n",
       " 0.49177728048214797,\n",
       " 0.5583340776813701,\n",
       " 0.25070598596889654,\n",
       " 0.47846202605627475]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Непустые значения нулевой строки\n",
    "[i for i in tfidf_ngram_features.todense()[0].getA1() if i>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda59c2f",
   "metadata": {},
   "source": [
    "### Решение задачи анализа тональности текста на основе модели \"мешка слов\"\n",
    "С использованием кросс-валидации попробуем применить к корпусу текстов различные варианты векторизации и классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb13aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, amazon_df['text'], amazon_df['value'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f9c46",
   "metadata": {},
   "source": [
    "### Классификаторы\n",
    "По варианту используем классификаторы \"LogisticRegression\" и \"Multinomial Naive Bayes - MNB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "923eddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '07': 2, '10': 3, '100': 4,\n",
      "                            '100x': 5, '11': 6, '1100sf': 7, '12': 8, '129': 9,\n",
      "                            '12am': 10, '15': 11, '150': 12, '18': 13, '19': 14,\n",
      "                            '1964': 15, '1990': 16, '1gb': 17, '1rst': 18,\n",
      "                            '1st': 19, '20': 20, '200': 21, '2000': 22,\n",
      "                            '2017': 23, '229': 24, '23': 25, '24': 26, '25': 27,\n",
      "                            '29': 28, '2nd': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.9257142857142857\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '07': 2, '10': 3, '100': 4,\n",
      "                            '100x': 5, '11': 6, '1100sf': 7, '12': 8, '129': 9,\n",
      "                            '12am': 10, '15': 11, '150': 12, '18': 13, '19': 14,\n",
      "                            '1964': 15, '1990': 16, '1gb': 17, '1rst': 18,\n",
      "                            '1st': 19, '20': 20, '200': 21, '2000': 22,\n",
      "                            '2017': 23, '229': 24, '23': 25, '24': 26, '25': 27,\n",
      "                            '29': 28, '2nd': 29, ...})\n",
      "Модель для классификации - MultinomialNB(alpha=0.5)\n",
      "Accuracy = 0.9219047619047619\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '07': 2, '10': 3, '100': 4,\n",
      "                            '100x': 5, '11': 6, '1100sf': 7, '12': 8, '129': 9,\n",
      "                            '12am': 10, '15': 11, '150': 12, '18': 13, '19': 14,\n",
      "                            '1964': 15, '1990': 16, '1gb': 17, '1rst': 18,\n",
      "                            '1st': 19, '20': 20, '200': 21, '2000': 22,\n",
      "                            '2017': 23, '229': 24, '23': 25, '24': 26, '25': 27,\n",
      "                            '29': 28, '2nd': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.921904761904762\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '07': 2, '10': 3, '100': 4,\n",
      "                            '100x': 5, '11': 6, '1100sf': 7, '12': 8, '129': 9,\n",
      "                            '12am': 10, '15': 11, '150': 12, '18': 13, '19': 14,\n",
      "                            '1964': 15, '1990': 16, '1gb': 17, '1rst': 18,\n",
      "                            '1st': 19, '20': 20, '200': 21, '2000': 22,\n",
      "                            '2017': 23, '229': 24, '23': 25, '24': 26, '25': 27,\n",
      "                            '29': 28, '2nd': 29, ...})\n",
      "Модель для классификации - MultinomialNB(alpha=0.5)\n",
      "Accuracy = 0.9168253968253968\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(C=3.0), MultinomialNB(alpha=0.5)]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d439663",
   "metadata": {},
   "source": [
    "### Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d962b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(amazon_df['text'], amazon_df['value'], test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c040e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03241b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.1171875\n",
      "1 \t 0.9986178299930891\n"
     ]
    }
   ],
   "source": [
    "sentiment(TfidfVectorizer(), LogisticRegression(C=3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcad0e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.4375\n",
      "1 \t 0.9854872149274361\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), LogisticRegression(C=3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f81adf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.0078125\n",
      "1 \t 0.9993089149965446\n"
     ]
    }
   ],
   "source": [
    "sentiment(TfidfVectorizer(), MultinomialNB(alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b7db9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.3671875\n",
      "1 \t 0.9847961299239807\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), MultinomialNB(alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06cc22",
   "metadata": {},
   "source": [
    "Лучшую точность показал CountVectorizer и LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198e95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
